{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633ce64b-eb6a-4dac-a9eb-bfb5a5d323db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import ast\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import math\n",
    "import re\n",
    "\n",
    "import dataframe_image as dfi\n",
    "import seaborn as sns\n",
    "import dateutil.relativedelta\n",
    "from io import BytesIO\n",
    "import win32clipboard\n",
    "from PIL import Image\n",
    "import sys\n",
    "import cv2\n",
    "import schedule\n",
    "import locale\n",
    "import zipfile\n",
    "import chromedriver_autoinstaller\n",
    "import io\n",
    "from io import StringIO\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f7c8b4-4929-4c20-a605-8a99d9113809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb29200-bb0e-4108-b34b-bf0a360165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for i in range(0,30):\n",
    "        while True:\n",
    "            try:\n",
    "                s = requests.Session()\n",
    "\n",
    "                s.headers.update({'authorization': 'Basic YXBpLWdhdGV3YXk6dGVzdA=='})\n",
    "\n",
    "                payload_login_man = {\"username\":\"irvin\", \"password\":\"@Indonesia2\", \"grant_type\":\"password\", \"scope\":\"read\"}\n",
    "\n",
    "                res_login_man = s.post('https://api.kupu.id/sso/oauth/token',  payload_login_man )\n",
    "                \n",
    "                print('Login Sucess')\n",
    "\n",
    "                s.headers.update({'authorization': 'Bearer '+  json.loads(res_login_man.content)['access_token']})\n",
    "                s.headers.update({'authorize-tag': 'bigdata'})\n",
    "                s.headers.update({'token': json.loads(res_login_man.content)['access_token']})\n",
    "                \n",
    "                params_idsp = {\"pageSize\": 40 , \"pageNum\":1}\n",
    "\n",
    "                res_idsp = s.get('https://bi.kupu.id/prod-api/bi/data/2/getPublicExportListToOv',  params = params_idsp )\n",
    "                \n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['downLoadPath']\n",
    "                    if 'job' in temp.lower() and 'detail' in temp.lower() and 'info' in temp.lower():\n",
    "                        link = temp     \n",
    "                \n",
    "                print('Downloading Job Detail Data')\n",
    "                \n",
    "                res_login_man = s.get(link)\n",
    "                \n",
    "                job_detail_df = pd.read_excel(res_login_man.content)\n",
    "                \n",
    "                today = pd.Timestamp('today')\n",
    "                \n",
    "                today = today - timedelta(days=1)\n",
    "                \n",
    "                today = today.replace(hour=23, minute=59, second=59, microsecond=999999)\n",
    "\n",
    "                print('JS Today: ' + str(today))\n",
    "\n",
    "                today_str = today.strftime('%Y-%m-%d')\n",
    "\n",
    "                first_day_of_month = today.replace(day=1).floor('D')\n",
    "\n",
    "                print('JS First Month: ' + str(first_day_of_month))\n",
    "\n",
    "                job_detail_df['time_of_post'] = pd.to_datetime(job_detail_df['time_of_post'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                mask = (job_detail_df['time_of_post'] >= first_day_of_month) & (job_detail_df['time_of_post'] <= today)\n",
    "                job_detail_this_month = job_detail_df.loc[mask]\n",
    "                job_detail_this_month = job_detail_this_month.reset_index(drop=True)\n",
    "                \n",
    "                job_detail_drop = job_detail_this_month.drop(columns=['user_job_id', 'payment',  'job_vacancy', 'job_description', 'job_type'])\n",
    "                \n",
    "                job_detail_accepted = job_detail_drop[job_detail_drop['accepted'] > 0]\n",
    "                \n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['downLoadPath']\n",
    "                    if 'job' in temp.lower() and 'provider' in temp.lower() and 'V' in temp:\n",
    "                        provider_link = temp\n",
    "                        \n",
    "                print('Downloading Job Provider Data')\n",
    "                        \n",
    "                res_provider = s.get(provider_link)\n",
    "                \n",
    "                job_provider_df = pd.read_excel(res_provider.content)\n",
    "                \n",
    "                job_provider_df_drop = job_provider_df[['full_name', 'job_provider_id', 'business_id', 'device_id']]\n",
    "                \n",
    "                job_provider_df_drop.columns = ['full_name', 'job_provider_id', 'business_id', 'jp_device_id']\n",
    "                \n",
    "                job_detail_and_provider = job_detail_accepted.merge(job_provider_df_drop, left_on='user_id', right_on='job_provider_id')\n",
    "                \n",
    "                business_id_list = job_detail_and_provider['business_id'].drop_duplicates().reset_index(drop = True)\n",
    "                \n",
    "                ended_lists = []\n",
    "                \n",
    "                print('Download Data from MAN KUPU 1')\n",
    "\n",
    "\n",
    "                for business_id in business_id_list:\n",
    "                    params_offered = {\"pageSize\": 500 , \"companyId\":business_id, \"businessId\":business_id, \"status\":7}\n",
    "\n",
    "                    res_offered = s.get('https://man.kupu.id/prod-api/position/offer/selectAllOfferByCompany',  params = params_offered )\n",
    "\n",
    "                    isi = json.loads(res_offered.content)\n",
    "\n",
    "                    if len(isi['body']['records']) == 0:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        for number in range(len(isi['body']['records'])):\n",
    "                            temp_list = [isi['body']['records'][number]['company']['id'] , isi['body']['records'][number]['job']['id'], isi['body']['records'][number]['company']['createUserId'], isi['body']['records'][number]['employee']['userId']]\n",
    "                            ended_lists.append(temp_list)\n",
    "                            \n",
    "                ended_df = pd.DataFrame(ended_lists, columns=['Business ID', 'Job ID', 'Provider ID', 'Seeker ID'])\n",
    "                \n",
    "                accepted_lists = []\n",
    "                \n",
    "                print('Download Data from MAN KUPU 2')\n",
    "\n",
    "\n",
    "                for business_id in business_id_list:\n",
    "                    params_offered = {\"pageSize\": 500 , \"companyId\":business_id, \"businessId\":business_id, \"status\":1}\n",
    "\n",
    "                    res_offered = s.get('https://man.kupu.id/prod-api/position/offer/selectAllOfferByCompany',  params = params_offered )\n",
    "\n",
    "                    isi = json.loads(res_offered.content)\n",
    "\n",
    "                    if len(isi['body']['records']) == 0:\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        for number in range(len(isi['body']['records'])):\n",
    "                            temp_list = [isi['body']['records'][number]['company']['id'] , isi['body']['records'][number]['job']['id'], isi['body']['records'][number]['company']['createUserId'], isi['body']['records'][number]['employee']['userId']]\n",
    "                            accepted_lists.append(temp_list)\n",
    "                            \n",
    "                accepted_df = pd.DataFrame(accepted_lists, columns=['Business ID', 'Job ID', 'Provider ID', 'Seeker ID'])\n",
    "                \n",
    "                all_accepted_df = ended_df.append(accepted_df, ignore_index=True)\n",
    "                \n",
    "                all_accepted_df_seeker_only = all_accepted_df[['Job ID', 'Seeker ID']]\n",
    "                \n",
    "                job_detail_and_provider['job_id'] = job_detail_and_provider['job_id'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker_id = job_detail_and_provider.merge(all_accepted_df_seeker_only, left_on = 'job_id', right_on = 'Job ID')\n",
    "                \n",
    "                print('Downloading Job Seekers Data')\n",
    "                \n",
    "                for i in range(len(json.loads(res_idsp.content)['rows'])):\n",
    "                    temp = json.loads(res_idsp.content)['rows'][i]['csvFilePath']\n",
    "                    if 'job' in temp.lower() and 'seeker' in temp.lower() and 'V' in temp and 'zip' in temp.lower():\n",
    "                        seeker_link = temp\n",
    "                \n",
    "                res_login_man = s.get(seeker_link)\n",
    "\n",
    "                man_byte = io.BytesIO(res_login_man.content)\n",
    "\n",
    "                zf = zipfile.ZipFile(man_byte, \"r\")\n",
    "\n",
    "                zip_file = zf.read(zf.namelist()[0])\n",
    "\n",
    "                zip_string =str(zip_file,'utf-8')\n",
    "\n",
    "                job_report = StringIO(zip_string) \n",
    "\n",
    "                job_seeker_df = pd.read_csv(job_report, index_col= 'no')\n",
    "                \n",
    "                job_seeker_df_name  = job_seeker_df[['user_id', 'full_name','device_id', 'mobile_number']]\n",
    "                \n",
    "                job_seeker_df_name.columns = ['user_id', 'full_name','js_device_id', 'mobile_number']\n",
    "                \n",
    "                job_seeker_df_name['user_id'] = job_seeker_df_name['user_id'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker = job_detail_and_provider_seeker_id.merge(job_seeker_df_name, left_on='Seeker ID', right_on='user_id')\n",
    "                \n",
    "                job_detail_and_provider_seeker_final = job_detail_and_provider_seeker[['business_id','business_name', 'job_id' , 'job_position', 'job_title', \n",
    "                                                                       'salary', 'city', 'applied' ,'offered','accepted','rejected',\n",
    "                                                                       'declined', 'time_of_post', 'time_of_accepted','job_provider_id', 'full_name_x',  \n",
    "                                                                       'jp_device_id', 'Seeker ID', 'full_name_y' , 'js_device_id', 'mobile_number']]\n",
    "                \n",
    "                job_detail_and_provider_seeker_final.columns = ['Business ID','Business Name', 'Job Post ID' , 'Job Position', 'Job Title', \n",
    "                                                                       'Salary', 'City', 'Applied' ,'Offered', 'Accepted', 'Rejected',\n",
    "                                                                       'Declined', 'Time of post', 'Time of accepted','Provider ID', 'Provider Name', 'Provider Device ID', 'Seeker ID', 'Seeker Name', 'Seeker Device ID', 'mobile_number']\n",
    "                                \n",
    "                business_group = job_detail_and_provider_seeker_final.groupby('Business ID')\n",
    "\n",
    "                business_id_list = job_detail_and_provider_seeker_final['Business ID'].unique()\n",
    "                \n",
    "                job_detail_and_provider_seeker_final['Multiple Device JS'] = False\n",
    "                job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] = 0\n",
    "\n",
    "                job_detail_and_provider_seeker_final['JP Same Device as JS'] = False\n",
    "                job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'] = 0\n",
    "\n",
    "                for ids in business_id_list:\n",
    "                    each_business_df = business_group.get_group(ids)\n",
    "                    job_post_id_list = each_business_df['Job Post ID'].unique()\n",
    "\n",
    "                    for job_post_id in job_post_id_list:\n",
    "                        business_job_post_group = each_business_df.groupby('Job Post ID')\n",
    "                        each_job_post_df = business_job_post_group.get_group(job_post_id)\n",
    "\n",
    "                        each_job_post_no_dup = each_job_post_df.drop_duplicates(subset=['Seeker ID'])\n",
    "                        divided_js_device_id = each_job_post_no_dup['Seeker Device ID'].str.split('，')\n",
    "                        all_divided_js_device_id = divided_js_device_id.explode('Seeker Device ID').dropna().unique()\n",
    "\n",
    "                        all_js_device_id = each_job_post_no_dup['Seeker Device ID']\n",
    "\n",
    "                        for js_device_id in all_divided_js_device_id:      \n",
    "\n",
    "                            js_occur = all_js_device_id.str.contains(js_device_id, na=False).sum()\n",
    "\n",
    "                            if js_occur > 1:\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['Multiple Device JS'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(js_device_id, na=False)) \n",
    "                                                                                                      & (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                      , True \n",
    "                                                                                                      , job_detail_and_provider_seeker_final['Multiple Device JS'])\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(js_device_id, na=False)) \n",
    "                                                                                                              & (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                              , job_detail_and_provider_seeker_final['Multiple Device JS (Count)'] + js_occur \n",
    "                                                                                                              , job_detail_and_provider_seeker_final['Multiple Device JS (Count)'])\n",
    "\n",
    "                        each_job_post_no_dup['Provider Device ID List'] = each_job_post_no_dup['Provider Device ID'].str.split(',')\n",
    "\n",
    "                        each_job_post_jp_exploded = each_job_post_no_dup.explode('Provider Device ID List')\n",
    "\n",
    "                        each_job_post_jp_exploded['Seeker Device ID List'] = each_job_post_jp_exploded['Seeker Device ID'].str.split('，')\n",
    "\n",
    "                        each_job_post_jp_js_exploded = each_job_post_jp_exploded.explode('Seeker Device ID List') \n",
    "\n",
    "                        duplicate_count = 0\n",
    "\n",
    "                        for row, data in each_job_post_jp_js_exploded.iterrows():\n",
    "\n",
    "                            if data['Provider Device ID List'] == data['Seeker Device ID List']:\n",
    "\n",
    "                                job_detail_and_provider_seeker_final['JP Same Device as JS'] = np.where((job_detail_and_provider_seeker_final['Seeker Device ID'].str.contains(data['Provider Device ID List'], na=False)) & \n",
    "                                                                                                        (job_detail_and_provider_seeker_final['Provider Device ID'].str.contains(data['Provider Device ID List'], na=False)) \n",
    "                                                                                                      , True \n",
    "                                                                                                      , job_detail_and_provider_seeker_final['JP Same Device as JS'])\n",
    "\n",
    "                                duplicate_count += 1\n",
    "\n",
    "                        job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'] = np.where((job_detail_and_provider_seeker_final['JP Same Device as JS'] == True) &\n",
    "                                                                                                        (job_detail_and_provider_seeker_final['Job Post ID'] == job_post_id) \n",
    "                                                                                                      , duplicate_count\n",
    "                                                                                                      , job_detail_and_provider_seeker_final['JP Same Device as JS (Count)'])\n",
    "                        \n",
    "                        job_detail_and_provider_seeker_final['Not Eligible']  = np.where((job_detail_and_provider_seeker_final['Multiple Device JS'] == True )  | (job_detail_and_provider_seeker_final['JP Same Device as JS'] == True )  , True , False )\n",
    "                        \n",
    "                job_detail_and_provider_seeker_final['Business ID'] = job_detail_and_provider_seeker_final['Business ID'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker_final['Provider ID'] = job_detail_and_provider_seeker_final['Provider ID'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker_final['mobile_number'] = job_detail_and_provider_seeker_final['mobile_number'].astype(str)\n",
    "                \n",
    "                job_detail_and_provider_seeker_final.to_excel('Job Match Fraud '+ today_str +'.xlsx', index = False)\n",
    "                \n",
    "                print('Save Fraud Data Sucess')\n",
    "                \n",
    "                business_group = job_detail_and_provider_seeker_final.groupby('Business ID')\n",
    "\n",
    "                business_id_list = job_detail_and_provider_seeker_final['Business ID'].unique()\n",
    "                \n",
    "                each_business_df_list = []\n",
    "\n",
    "                for ids in business_id_list:\n",
    "                    each_business_df = business_group.get_group(ids)\n",
    "                    business_name = each_business_df['Business Name'].iloc[0]\n",
    "                    accept_amount = each_business_df.shape[0]\n",
    "                    not_eligible_amount = each_business_df[each_business_df['Not Eligible'] == True].shape[0]\n",
    "                    eligible_amount = accept_amount - not_eligible_amount\n",
    "\n",
    "                    each_business_df_list.append([ids, business_name, accept_amount, eligible_amount, not_eligible_amount])\n",
    "                    \n",
    "                headers = ['Business ID', 'Business Name', 'Accept Amount', 'Eligible Amount', 'Not Eligible Amount' ]\n",
    "                \n",
    "                result_dataframe = pd.DataFrame(each_business_df_list, columns = headers)\n",
    "                \n",
    "                result_dataframe['Business ID'] = result_dataframe['Business ID'].astype(str)\n",
    "                \n",
    "                result_dataframe.to_excel('Job Match Fraud Summary '+ today_str +'.xlsx', index = False)\n",
    "                \n",
    "                break\n",
    "\n",
    "            except:\n",
    "                print('Job Match Processing Error, retrying in 30s')\n",
    "                time.sleep(30)\n",
    "\n",
    "                continue\n",
    "\n",
    "        break\n",
    "        \n",
    "    for i in range(0,10):\n",
    "        while True:\n",
    "            try:\n",
    "                path = chromedriver_autoinstaller.install() \n",
    "\n",
    "                chromeOptions = webdriver.ChromeOptions()\n",
    "                chromeOptions.add_argument(\"--start-maximized\")\n",
    "                s = Service(path)\n",
    "                driver = webdriver.Chrome(service=s, options=chromeOptions)\n",
    "\n",
    "                driver.get(\"https://mail.dalligent.com/\")\n",
    "\n",
    "                WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//input[@name='account_name']\")))\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@name='account_name']\").send_keys('irvin.andersen')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@name='password']\").send_keys('Indonesia2')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@class='form-btn']\").click()\n",
    "\n",
    "                WebDriverWait(driver, 120).until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(),'写 信')]/..\")))\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//*[contains(text(),'写 信')]/..\").click()\n",
    "\n",
    "                WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='js-component-emailcontainer nui-multiLineIpt C-multiLineIpt nui-ipt']\")))\n",
    "                \n",
    "                yesterday = today - timedelta(days=1)\n",
    "\n",
    "                yesterday_mail = yesterday.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[contains(@id,'subjectInput')]\").send_keys('BD Job Match Fraud ' + today_str)\n",
    "      \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('tannya.madrim@dalligent.com ')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('sendhy.desmijaya@dalligent.com ')\n",
    "            \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('felicya.febrina@dalligent.com ')\n",
    "                \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('mochammad.hidayah@dalligent.com ')\n",
    "                \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('riyan.fermansyah@dalligent.com ')\n",
    "                \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('tiara.marcellia@dalligent.com ')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('keenan.pasha@dalligent.com ')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('gladys.elisiafin@dalligent.com ')\n",
    "                \n",
    "                driver.find_element(By.XPATH, \"//input[@class='nui-editableAddr-ipt']\").send_keys('copper.quan@dalligent.com ')\n",
    "                \n",
    "                try:\n",
    "                    driver.find_element(By.XPATH, \"//span[contains(text(),'我知道了')]\").click()\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='APP-editor APP-editor-basic']\")))\n",
    "                \n",
    "                driver.find_element(By.XPATH, \"//div[@class='APP-editor APP-editor-basic']\").click()\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//b[@class='ico ico-editor ico-editor-image']\").click()\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//span[contains(text(),'浏览')]\").click()\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@type='file']\").send_keys(os.getcwd() + \"/\" + 'Job Match Fraud '+ today_str +'.xlsx')\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//b[@class='ico ico-editor ico-editor-image']\").click()\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//span[contains(text(),'浏览')]\").click()\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//input[@type='file']\").send_keys(os.getcwd()+ \"/\"+ 'Job Match Fraud Summary '+ today_str +'.xlsx')\n",
    "                \n",
    "\n",
    "                WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//span[text() = '发送']\")))\n",
    "\n",
    "                time.sleep(5)\n",
    "\n",
    "                driver.find_element(By.XPATH, \"//span[text() = '发送']\").click()\n",
    "\n",
    "                time.sleep(300)\n",
    "                \n",
    "                break\n",
    "                \n",
    "            except:\n",
    "                print('Email Send Error, retrying in 30s')\n",
    "                time.sleep(30)\n",
    "                \n",
    "                continue\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51a9eb6-c89f-43c1-984a-67d328f32b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucess\n",
      "Downloading Job Detail Data\n",
      "JS Today: 2022-07-24 23:59:59.999999\n",
      "JS First Month: 2022-07-01 00:00:00\n",
      "Downloading Job Provider Data\n",
      "Download Data from MAN KUPU 1\n",
      "Download Data from MAN KUPU 2\n",
      "Downloading Job Seekers Data\n",
      "Save Fraud Data Sucess\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fca5dec-c996-4607-93f9-f70ac44c02c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 day at 07:00:00 do run() (last run: [never], next run: 2022-07-26 07:00:00)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.every().day.at(\"07:00\").do(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00860a6-a614-421b-8dd4-2761b63b511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucess\n",
      "Downloading Job Detail Data\n",
      "JS Today: 2022-07-25 23:59:59.999999\n",
      "JS First Month: 2022-07-01 00:00:00\n",
      "Downloading Job Provider Data\n",
      "Download Data from MAN KUPU 1\n",
      "Download Data from MAN KUPU 2\n",
      "Downloading Job Seekers Data\n",
      "Save Fraud Data Sucess\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60) # wait one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9220b7-79bd-4e72-bdcb-6350c98b4039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
